{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the required Libraries.\n",
    "import _pickle as pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from typing import Optional, TextIO, Type, Tuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Training_Data = 'Dota_2.vp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Training_Data, 'rb') as File:\n",
    "    D = pickle.Unpickler(File)\n",
    "    Data = D.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Team 1’s hero IDs of 54400 matches. \n",
    "Data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Team 0’s hero IDs of 54400 matches.\n",
    "Data[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Team 1’s stats of 54400 matches.\n",
    "Data[2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Team 0’s stats of 54400 matches.\n",
    "Data[3][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match result of 54400 matches.\n",
    "# Format (Team ID that won the game, duration of the game)\n",
    "Data[4][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_categorical(n, num_classes: Optional[int] = None) -> np.ndarray:\n",
    "    \"\"\"Encode to categorical data.\"\"\"\n",
    "    if not (type(n) is np.ndarray):\n",
    "        if type(n) is list:\n",
    "            n = np.array(n)\n",
    "        else:\n",
    "            n = np.array([n])\n",
    "    if len(n.shape) > 1:\n",
    "        raise ValueError(\"To many dimensions\")\n",
    "    n = n.astype(np.int)\n",
    "    if num_classes is None:\n",
    "        num_classes = np.max(n) + 1\n",
    "    encoded = np.zeros([len(n), num_classes])\n",
    "    encoded[np.arange(len(n)), n] = 1\n",
    "    return encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(np.array(Data[1]).flatten()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hero_ids = np.unique(np.array(Data[1]).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(np.array(Data[1]).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = np.max(np.array(Data[1]).flatten())+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_teams(team1,team2):\n",
    "    ret = np.zeros([1, num_classes])\n",
    "    for e1 in team1:\n",
    "        ret += to_categorical(e1, num_classes)\n",
    "    for e2 in team2 :\n",
    "        ret -= to_categorical(e2, num_classes)\n",
    "    return ret\n",
    "encode_teams(Data[0][0], Data[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = np.concatenate([encode_teams(Data[0][i], Data[1][i]) for i in range(len(Data[0]))], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = np.array([Data[4][i][0] for i in range(len(Data[0]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndata = len(inputs)\n",
    "nvalid = ndata//10\n",
    "indexes = np.random.permutation(ndata)\n",
    "validation_indexes = indexes[:nvalid]\n",
    "train_indexes = indexes[nvalid:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train = inputs[train_indexes]\n",
    "inputs_valid = inputs[validation_indexes]\n",
    "outputs_train = outputs[train_indexes]\n",
    "outputs_valid = outputs[validation_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.layers import (Activation, BatchNormalization, Dense,\n",
    "                                     Input, Lambda, LeakyReLU, Reshape)\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#     def mlp2_block(self, x, neurons: int, outshape: int):\n",
    "#         \"\"\"Two linear layers multilayer perceptron.\"\"\"\n",
    "#         x = Dense(neurons)(x)\n",
    "#         x = BatchNormalization()(x)\n",
    "#         x = LeakyReLU()(x)\n",
    "#         x = Dense(outshape)(x)\n",
    "#         x = BatchNormalization()(x)\n",
    "#         x = LeakyReLU()(x)\n",
    "\n",
    "#         return x\n",
    "\n",
    "neurons = 256\n",
    "input_h = Input(shape=(120))\n",
    "\n",
    "x = Dense(neurons)(input_h)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Dense(neurons)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Dense(1)(x)\n",
    "out_f = Activation(\"sigmoid\")(x)\n",
    "\n",
    "model = Model(inputs=input_h, outputs=out_f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[\"mae\", \"acc\"])  # Is mse the right loss?\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Tensorboard\n",
    "# tfdir = PATH_SUMMARIES() / Path(name)\n",
    "\n",
    "# safe_rm(tfdir)\n",
    "# tfdir.mkdir(parents=True, exist_ok=False)\n",
    "# tbCallBack = TensorBoard(log_dir=str(tfdir), histogram_freq=0, write_graph=True, write_images=True, update_freq=128)\n",
    "\n",
    "# # Save Callback\n",
    "# cpdir = PATH_CHECKPOINTS() / Path(name)\n",
    "# safe_rm(cpdir)\n",
    "# cpdir.mkdir(parents=True, exist_ok=False)\n",
    "\n",
    "# svCallBack = ModelCheckpoint(str(cpdir / \"model-{epoch:02d}-{val_loss:.2f}-{val_acc:.2f}.hdf5\"), monitor=\"val_acc\", verbose=0, save_best_only=False, save_weights_only=False, mode=\"auto\", period=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model.fit(q_gen_train, steps_per_epoch=4*1024, epochs=epochs, validation_data=q_gen_valid, validation_steps=256, callbacks=[tbCallBack, svCallBack])\n",
    "history = model.fit(x = inputs_train, y = outputs_train, batch_size=64, validation_data=(inputs_valid, outputs_valid), epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "y_true = outputs_valid\n",
    "y_scores = res = model.predict(x = inputs_valid, batch_size=64 )\n",
    "roc_auc = roc_auc_score(y_true, y_scores)\n",
    "fpr, tpr, threshold = roc_curve(y_true, y_scores)\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let us add more output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_time = np.array([Data[4][i][1] for i in range(len(Data[0]))])\n",
    "game_time_std = np.std(game_time)\n",
    "game_time_mean = np.mean(game_time)\n",
    "game_time = (game_time-game_time_mean)/game_time_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(game_time, 100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs2 = np.array([outputs, game_time]).T\n",
    "outputs_train = outputs2[train_indexes]\n",
    "outputs_valid = outputs2[validation_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons = 256\n",
    "input_h = Input(shape=(120))\n",
    "\n",
    "x = Dense(neurons)(input_h)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Dense(neurons)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "out_f = Dense(2)(x)\n",
    "# out_f = Activation(\"sigmoid\")(x)\n",
    "\n",
    "model = Model(inputs=input_h, outputs=out_f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[\"mae\", \"acc\"])  # Is mse the right loss?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x = inputs_train, y = outputs_train, batch_size=64, validation_data=(inputs_valid, outputs_valid), epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.predict(x = inputs_valid, batch_size=64 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = np.mean(np.abs(res[:,0]>0.5 - outputs_valid[:,0]))\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.mean(np.abs(res[:,1] - outputs_valid[:,1]))\n",
    "t*game_time_std/60, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - np.mean(np.abs(1*(res[:,0]>0.5) - outputs_valid[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1-np.mean(np.logical_xor(res[:,0]>0.5, outputs_valid[:,0]>0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "y_true = outputs_valid[:,0]\n",
    "y_scores = res[:,0]\n",
    "roc_auc = roc_auc_score(y_true, y_scores)\n",
    "fpr, tpr, threshold = roc_curve(y_true, y_scores)\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model using everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_teams(team1,team2, st=0):\n",
    "    ret = np.zeros([20, num_classes])\n",
    "    for i, (e1, e2) in enumerate(zip(team1, team2)):\n",
    "        r1 = to_categorical(e1, num_classes)\n",
    "        r2 = to_categorical(e2, num_classes)\n",
    "        if i==0:\n",
    "            ret[4*i+0,:] = r1\n",
    "            ret[4*i+1,:] = r2\n",
    "        else:\n",
    "            ret[4*i+0,:] = ret[4*(i-1)+2,:] + r1\n",
    "            ret[4*i+1,:] = ret[4*(i-1)+3,:] + r2\n",
    "        ret[4*i+2,:] = ret[4*i+0,:] - r2\n",
    "        ret[4*i+3,:] = ret[4*i+1,:] - r1\n",
    "    return ret[ 4*st:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = encode_teams(Data[0][0], Data[1][0])\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(encode_teams(np.arange(5), np.arange(5)+5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = 0\n",
    "inputs = np.concatenate([encode_teams(Data[0][i], Data[1][i], st) for i in range(len(Data[0]))], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.mod(np.arange(20-st*4), 2)\n",
    "outputs = np.concatenate([np.abs(t-Data[4][i][0]) for i in range(len(Data[0]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndata = len(inputs)\n",
    "nvalid = ndata//10\n",
    "indexes = np.random.permutation(ndata)\n",
    "validation_indexes = indexes[:nvalid]\n",
    "train_indexes = indexes[nvalid:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train = inputs[train_indexes]\n",
    "inputs_valid = inputs[validation_indexes]\n",
    "outputs_train = outputs[train_indexes]\n",
    "outputs_valid = outputs[validation_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def data_gen(t1, t2, outs)\n",
    "#     st = 4\n",
    "#     for team1, team2, out in zip(t1,t2, outs):\n",
    "#         ret = encode_teams(team1, team2)\n",
    "#         t = -(np.mod(np.arange(20-4*st), 2)*2-1) * out[0]\n",
    "#         outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons = 256\n",
    "input_h = Input(shape=(120))\n",
    "\n",
    "x = Dense(neurons)(input_h)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Dense(neurons)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU()(x)\n",
    "x = Dense(1)(x)\n",
    "out_f = Activation(\"sigmoid\")(x)\n",
    "\n",
    "model = Model(inputs=input_h, outputs=out_f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=[\"mae\", \"acc\"])  # Is mse the right loss?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x = inputs_train, y = outputs_train, batch_size=512, shuffle=True, validation_data=(inputs_valid, outputs_valid), epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = []\n",
    "num_pick = np.arange(1,11)\n",
    "num_pick_input = np.sum(np.abs(inputs_valid), axis=1)\n",
    "for i in num_pick:\n",
    "    mask = num_pick_input==i\n",
    "    masks.append(mask)\n",
    "    if np.sum(mask):\n",
    "        res = model.evaluate(x = inputs_valid[mask], y=outputs_valid[mask], batch_size=512,verbose=0)\n",
    "        print(i, res[-1])\n",
    "        res = model.predict(x = inputs_valid[mask], batch_size=512,verbose=0)\n",
    "        score, ideal_score, nb_matches = compute_calibration_from_pred(res.flatten(), outputs_valid[mask])\n",
    "        plt.figure()\n",
    "        x = np.arange(10)/20+0.55\n",
    "        plt.plot(x, score, \"x-\")\n",
    "        plt.plot(x, ideal_score,  \"o-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_calibration_from_pred(\n",
    "    p: np.array, target: np.array, nbins: int = 10\n",
    ") -> Tuple[np.array, np.array, np.array]:\n",
    "    \"\"\"Compute calibration from prediction.\"\"\"\n",
    "    correct = (1*(p>0.5) - target) == 0\n",
    "    confidence = np.abs(p*2-1) / 2 + 0.5\n",
    "    score = np.zeros([nbins])\n",
    "    ideal_score = np.zeros([nbins])\n",
    "    nb_matches = np.zeros([nbins])\n",
    "    for i in range(nbins):\n",
    "        low = 0.5 + i * 0.5 / nbins\n",
    "        high = 0.5 + (i + 1) * 0.5 / nbins\n",
    "        interval = np.logical_and(confidence <= high, confidence >= low)\n",
    "        n_match = np.sum(interval)\n",
    "        if n_match:\n",
    "            score[i] = np.mean(correct[interval])\n",
    "            ideal_score[i] = np.mean(confidence[interval])\n",
    "        else:\n",
    "            score[i] = np.nan\n",
    "            ideal_score[i] = (low + high) / 2\n",
    "        nb_matches[i] = n_match\n",
    "    return score, ideal_score, nb_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confidence = np.abs(res.flatten()*2-1) / 2 + 0.5\n",
    "# plt.hist(confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.predict(x = inputs_valid, batch_size=512,verbose=0)\n",
    "score, ideal_score, nb_matches = compute_calibration_from_pred(res.flatten(), outputs_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make the next pick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Take a real example\n",
    "pick = 6\n",
    "mask = masks[pick-1]\n",
    "select_ind = np.random.randint(np.sum(mask))\n",
    "sample = inputs_valid[mask][select_ind]\n",
    "np.sum(np.abs(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute all possible probabilities\n",
    "possible_samples = []\n",
    "corresponding_ids = []\n",
    "for i in hero_ids:\n",
    "    if sample[i]==0:\n",
    "        new_sample = sample.copy()\n",
    "        if np.mod(np.sum(np.abs(sample)),2)==0:\n",
    "            new_sample[i] = 1\n",
    "        else:\n",
    "            new_sample[i] = -1\n",
    "        corresponding_ids.append(i)\n",
    "        possible_samples.append(new_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = model.predict(x=np.array(possible_samples)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,p in zip(corresponding_ids, prob):\n",
    "    print(i,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
